locals {
  topics_confluent_cloud_url = "https://confluent.cloud/environments/${data.confluent_environment.staging.id}/clusters/${confluent_kafka_cluster.freight.id}/topics?topics_filter=showAll"
}

output "instructions" {
  value = <<-EOT
  Environment ID:   ${data.confluent_environment.staging.id}
  Kafka Cluster ID: ${confluent_kafka_cluster.freight.id}
  Kafka topic name: ${local.topic_name}

  Service Accounts and their Kafka API Keys (API Keys inherit the permissions granted to the owner):
  ${confluent_service_account.app-manager.display_name}:                     ${confluent_service_account.app-manager.id}
  ${confluent_service_account.app-manager.display_name}'s Kafka API Key:     "${confluent_api_key.app-manager-kafka-api-key.id}"
  ${confluent_service_account.app-manager.display_name}'s Kafka API Secret:  "${confluent_api_key.app-manager-kafka-api-key.secret}"

  ${confluent_service_account.app-producer.display_name}:                    ${confluent_service_account.app-producer.id}
  ${confluent_service_account.app-producer.display_name}'s Kafka API Key:    "${confluent_api_key.app-producer-kafka-api-key.id}"
  ${confluent_service_account.app-producer.display_name}'s Kafka API Secret: "${confluent_api_key.app-producer-kafka-api-key.secret}"

  ${confluent_service_account.app-consumer.display_name}:                    ${confluent_service_account.app-consumer.id}
  ${confluent_service_account.app-consumer.display_name}'s Kafka API Key:    "${confluent_api_key.app-consumer-kafka-api-key.id}"
  ${confluent_service_account.app-consumer.display_name}'s Kafka API Secret: "${confluent_api_key.app-consumer-kafka-api-key.secret}"

  üîë SSH SETUP INSTRUCTIONS:

  1. First, save your private key:
     echo '${tls_private_key.main.private_key_pem}' > ~/.ssh/pni-test-key.pem

  2. Set correct permissions on the private key:
     chmod 600 ~/.ssh/pni-test-key.pem

  3. Verify the key file permissions and content:
     ls -la ~/.ssh/pni-test-key.pem
     head -n 1 ~/.ssh/pni-test-key.pem  # Should show "-----BEGIN RSA PRIVATE KEY-----" or similar

  4. Connect to your EC2 instance:
     ssh -i ~/.ssh/pni-test-key.pem ec2-user@${aws_instance.test.public_ip}

  üìù Note: The private key is automatically generated by Terraform.

  5. Test connectivity (port 443):
    curl --request GET \
    --url ${confluent_kafka_cluster.freight.rest_endpoint}/kafka/v3/clusters/${confluent_kafka_cluster.freight.id}/topics \
    -u "${confluent_api_key.app-manager-kafka-api-key.id}:${confluent_api_key.app-manager-kafka-api-key.secret}"

  6. Testing installation commands:

  # First, check if user_data script ran successfully
  sudo cat /var/log/cloud-init-output.log | tail -20  # Check for any errors during boot
  sudo cat /var/log/user-data.log | tail -20  # Check for any errors during boot

  # Verify Confluent CLI installation
  confluent version

  # Verify Terraform installation
  terraform version

  üèóÔ∏è TERRAFORM SETUP INSTRUCTIONS:

  1. Create main.tf file on your EC2 instance with the following content:

     cat << 'MAINEOF' > main.tf
terraform {
  required_version = ">= 0.14.0"
  required_providers {
    confluent = {
      source  = "confluentinc/confluent"
      version = "2.40.0"
    }
  }
}

provider "confluent" {
  kafka_id            = "${confluent_kafka_cluster.freight.id}"
  kafka_rest_endpoint = "${confluent_kafka_cluster.freight.rest_endpoint}"
  kafka_api_key       = "${confluent_api_key.app-manager-kafka-api-key.id}"
  kafka_api_secret    = "${confluent_api_key.app-manager-kafka-api-key.secret}"
}

resource "confluent_kafka_topic" "orders" {
  topic_name    = "${local.topic_name}"
  lifecycle {
    prevent_destroy = true
  }
}
MAINEOF
  2. Initialize and apply Terraform:
     terraform init
     terraform apply


  In order to use the Confluent CLI v4 to produce and consume messages from topic '${local.topic_name}' using Kafka API Keys
  of ${confluent_service_account.app-producer.display_name} and ${confluent_service_account.app-consumer.display_name} service accounts
  run the following commands:

  # 1. Log in to Confluent Cloud
  $ confluent login

  # 2. Produce key-value records to topic '${local.topic_name}' by using ${confluent_service_account.app-producer.display_name}'s Kafka API Key
  $ confluent kafka topic produce ${local.topic_name} --environment ${data.confluent_environment.staging.id} --cluster ${confluent_kafka_cluster.freight.id} --api-key "${confluent_api_key.app-producer-kafka-api-key.id}" --api-secret "${confluent_api_key.app-producer-kafka-api-key.secret}" --bootstrap "${confluent_kafka_cluster.freight.bootstrap_endpoint}"
  # Enter a few records and then press 'Ctrl-C' when you're done.
  # Sample records:
  # {"number":1,"date":18500,"shipping_address":"899 W Evelyn Ave, Mountain View, CA 94041, USA","cost":15.00}
  # {"number":2,"date":18501,"shipping_address":"1 Bedford St, London WC2E 9HG, United Kingdom","cost":5.00}
  # {"number":3,"date":18502,"shipping_address":"3307 Northland Dr Suite 400, Austin, TX 78731, USA","cost":10.00}

  # 3. Consume records from topic '${local.topic_name}' by using ${confluent_service_account.app-consumer.display_name}'s Kafka API Key
  $ confluent kafka topic consume ${local.topic_name} --from-beginning --environment ${data.confluent_environment.staging.id} --cluster ${confluent_kafka_cluster.freight.id} --api-key "${confluent_api_key.app-consumer-kafka-api-key.id}" --api-secret "${confluent_api_key.app-consumer-kafka-api-key.secret}" --bootstrap "${confluent_kafka_cluster.freight.bootstrap_endpoint}"
  # When you are done, press 'Ctrl-C'.

  üîë CONFLUENT CLOUD CONSOLE ACCESS INSTRUCTIONS:

  1. Exit the EC2 SSH session.

  2. You should see "Create topic" button grayed out on ${local.topics_confluent_cloud_url}.

  3. Update the /etc/hosts file on your laptop (the NGINX proxy was set up via Terraform already):
     echo "\n${aws_instance.test.public_ip} ${trimprefix(trimsuffix(confluent_kafka_cluster.freight.rest_endpoint, ":443"), "https://")}" | sudo tee -a /etc/hosts

  4. You should now see the "orders" topic on ${local.topics_confluent_cloud_url}.

  5. (Optional) Alternatively, you can also send a direct cURL request from your laptop to verify the NGINX proxy was set up correctly:

    curl --request GET \
    --url ${confluent_kafka_cluster.freight.rest_endpoint}/kafka/v3/clusters/${confluent_kafka_cluster.freight.id}/topics \
    -u "${confluent_api_key.app-manager-kafka-api-key.id}:${confluent_api_key.app-manager-kafka-api-key.secret}"


  5. For more details,
     see https://docs.confluent.io/cloud/current/networking/ccloud-console-access.html#configure-a-proxy for more details.

  EOT

  sensitive = true
}
