---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "confluent_flink_connection Data Source - terraform-provider-confluent"
subcategory: ""
description: |-
  
---

# confluent_flink_connection Data Source

[![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)

`confluent_flink_connection` describes a Flink Connection data source.

## Example Usage

### Option #1: Manage multiple Flink Compute Pools in the same Terraform workspace

```terraform
provider "confluent" {
  cloud_api_key    = var.confluent_cloud_api_key    # optionally use CONFLUENT_CLOUD_API_KEY env var
  cloud_api_secret = var.confluent_cloud_api_secret # optionally use CONFLUENT_CLOUD_API_SECRET env var
}

data "confluent_flink_connection" "main" {
  organization {
    id = data.confluent_organization.main.id
  }
  environment {
    id = data.confluent_environment.staging.id
  }
  compute_pool {
    id = confluent_flink_compute_pool.example.id
  }
  principal {
    id = confluent_service_account.app-manager-flink.id
  }
  rest_endpoint = data.confluent_flink_region.main.rest_endpoint
  credentials {
    key    = confluent_api_key.env-admin-flink-api-key.id
    secret = confluent_api_key.env-admin-flink-api-key.secret
  }
  display_name = "connection1"
  type = "OPENAI"
}

output "connection_output" {
  value = data.confluent_flink_connection.main.
}
```

### Option #2: Manage a single Kafka cluster in the same Terraform workspace

```terraform
provider "confluent" {
  organization_id       = var.organization_id            # optionally use CONFLUENT_ORGANIZATION_ID env var
  environment_id        = var.environment_id             # optionally use CONFLUENT_ENVIRONMENT_ID env var
  flink_compute_pool_id = var.flink_compute_pool_id      # optionally use FLINK_COMPUTE_POOL_ID env var
  flink_rest_endpoint   = var.flink_rest_endpoint        # optionally use FLINK_REST_ENDPOINT env var
  flink_api_key         = var.flink_api_key              # optionally use FLINK_API_KEY env var
  flink_api_secret      = var.flink_api_secret           # optionally use FLINK_API_SECRET env var
  flink_principal_id    = var.flink_principal_id         # optionally use FLINK_PRINCIPAL_ID env var
}

data "confluent_flink_connection" "main" {
  display_name = "connection1"
  type = "OPENAI"
}

output "connection_output" {
  value = data.confluent_flink_connection.main.
}
```

<!-- schema generated by tfplugindocs -->
## Argument Reference

The following arguments are supported:

- `organization` (Optional Configuration Block) supports the following:
    - `id` - (Required String) The ID of the Organization, for example, `1111aaaa-11aa-11aa-11aa-111111aaaaaa`.
- `environment` (Optional Configuration Block) supports the following:
    - `id` - (Required String) The ID of the Environment, for example, `env-abc123`.
- `compute_pool` - (Optional Configuration Block) supports the following:
    - `id` - (Required String) The ID of the Flink Compute Pool, for example, `lfcp-abc123`.
- `principal` - (Optional Configuration Block) supports the following:
    - `id` - (Required String) The ID of the Principal the Flink Connection runs as, for example, `sa-abc123`.
- `rest_endpoint` - (Optional String) The REST endpoint of the Flink region, for example, `https://flink.us-east-1.aws.confluent.cloud`).
- `credentials` (Optional Configuration Block) supports the following:
    - `key` - (Required String) The Flink API Key.
    - `secret` - (Required String, Sensitive) The Flink API Secret.

-> **Note:** A Flink API key consists of a key and a secret. Flink API keys are required to interact with Flink Connections in Confluent Cloud. Each Flink API key is valid for one specific Flink Region.

-> **Note:** Use Option #2 to simplify the key rotation process. When using Option #1, to rotate a Flink API key, create a new Flink API key, update the `credentials` block in all configuration files to use the new Flink API key, run `terraform apply -target="confluent_flink_connection.example"`, and remove the old Flink API key. Alternatively, in case the old Flink API Key was deleted already, you might need to run `terraform plan -refresh=false -target="confluent_flink_connection.example" -out=rotate-flink-api-key` and `terraform apply rotate-flink-api-key` instead.

- `display_name` - (Required String) The name of the Flink Connection.
- `type` - (Optional String) The type of the Flink Connection. The accepted values are: `OPENAI`, `AZUREML`, `AZUREOPENAI`, `BEDROCK`, `SAGEMAKER`, `GOOGLEAI`, `VERTEXAI`, `MONGODB`, `PINECONE`, `ELASTIC` and `COUCHBASE`.

## Attributes Reference

In addition to the preceding arguments, the following attributes are exported:

- `endpoint` - (Required String) The endpoint of the Flink Connection, for example, `https://api.openai.com/v1/chat/completions`
- `data` - (Required String) The authentication data of the Flink Connection.
- `status` - (Required String) The status of the Flink Connection.
- `status_detail` - (Required String) The status details of the Flink Connection.
- 