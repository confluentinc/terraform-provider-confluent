---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "confluent_kafka_client_quota Resource - terraform-provider-confluent"
subcategory: ""
description: |-
  
---

# confluent_kafka_client_quota Resource

[![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy) [![Request Access To Client Quotas API](https://img.shields.io/badge/-Request%20Access%20To%20Clients%20Quotas-%23bc8540)](mailto:cloud-client-quotas-ea@confluent.io?subject=Request%20to%20join%20Kafka%20Quotas%20Management%20API%20Early%20Access&amp;body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20kafka-quotas/v1%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

-> **Note:** `confluent_kafka_client_quota` resource is available in **Early Access** for early adopters. Early Access features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.  
**Early Access** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Early Access features. Early Access features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Early Access features at any time in Confluentâ€™s sole discretion.

`confluent_kafka_client_quota` provides a Kafka Client Quota resource that enables creating, editing, and deleting Kafka Client Quotas on Confluent Cloud.

-> **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.

-> **Note:** It is recommended to set `lifecycle { prevent_destroy = true }` on production instances to prevent accidental Kafka Client Quotas deletion. This setting rejects plans that would destroy or recreate the Kafka Client Quota, such as attempting to change uneditable attributes. Read more about it in the [Terraform docs](https://www.terraform.io/language/meta-arguments/lifecycle#prevent_destroy).

## Example Usage

```terraform
resource "confluent_kafka_client_quota" "example" {
  display_name = "test-quota"
  description  = "Test Quota"
  throughput {
    ingress_byte_rate = "100"
    egress_byte_rate  = "200"
  }
  principals = [confluent_service_account.app_manager.id, confluent_service_account.app_manager_2.id]

  kafka_cluster {
    id = confluent_kafka_cluster.dedicated.id
  }
  environment {
    id = confluent_environment.development.id
  }
  
  lifecycle {
    prevent_destroy = true
  }
}
```

<!-- schema generated by tfplugindocs -->
## Argument Reference

The following arguments are supported:

- `display_name` - (Required String) The name of the Kafka Client Quota.
- `description` - (Optional String) The description of the Kafka Client Quota.
- `throughput` (Required Configuration Block) supports the following:
  - `ingress_byte_rate` - (Optional String) The ingress throughput limit in bytes per second.
  - `egress_byte_rate` - (Optional String) The egress throughput limit in bytes per second.
- `principals` - (Required Set of Strings) The list of service accounts to apply the Kafka Client Quota to. Use the special name, "default",  to represent the default quota for all users and service accounts.
- `kafka_cluster` (Required Configuration Block) supports the following:
  - `id` - (Required String) The ID of the Kafka Cluster where the Kafka Client Quota is applied, for example, `lkc-abc123`.
- `environment` (Required Configuration Block) supports the following:
  - `id` - (Required String) The ID of the Environment that the corresponding Kafka Cluster belongs to, for example, `env-abc123`.

-> **Note:** Each principal assigned to a quota receives the full amount of the quota, meaning the quota is not shared by the principals it is assigned. For example, if a 10 MBps ingress quota is applied to Principals 1 and 2, Principal 1 can produce at most 10 MBps, independently of Principal 2.

-> **Note:** Define a throughput maximum, but do not guarantee a throughput floor. Applications are rate-limited through the use of the Kafka throttling mechanism. Kafka asks the client to wait before sending more data and mutes the channel, which appears as latency to the client application.

## Attributes Reference

In addition to the preceding arguments, the following attributes are exported:

- `id` - (Required String) The ID of the Kafka Client Quota, for example, `cq-abc123`.

## Import

-> **Note:** `CONFLUENT_CLOUD_API_KEY` and `CONFLUENT_CLOUD_API_SECRET` environment variables must be set before importing a Kafka Client Quota.

You can import a Kafka Client Quota by using Kafka Client Quota ID. The following example shows how to import a Kafka Client Quota ID:

```shell
$ export CONFLUENT_CLOUD_API_KEY="<cloud_api_key>"
$ export CONFLUENT_CLOUD_API_SECRET="<cloud_api_secret>"
$ terraform import confluent_kafka_client_quota.example cq-abc123
```

!> **Warning:** Do not forget to delete terminal command history afterwards for security purposes.
