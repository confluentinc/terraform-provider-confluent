---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "confluent_flink_compute_pool Resource - terraform-provider-confluent"
subcategory: ""
description: |-
  
---

# confluent_flink_compute_pool Resource

[![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)

-> **Note:** `confluent_flink_compute_pool` resource is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.  
**Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing Preview releases of the Preview features at any time in Confluentâ€™s sole discretion.

`confluent_flink_compute_pool` provides a Flink Compute Pool resource that enables creating, editing, and deleting Flink Compute Pool on Confluent Cloud.

-> **Note:** It is recommended to set `lifecycle { prevent_destroy = true }` on production instances to prevent accidental Flink Compute Pool deletion. This setting rejects plans that would destroy or recreate the Flink Compute Pool, such as attempting to change uneditable attributes. Read more about it in the [Terraform docs](https://www.terraform.io/language/meta-arguments/lifecycle#prevent_destroy).

## Example Usage

```terraform
resource "confluent_environment" "development" {
  display_name = "Development"
}

resource "confluent_flink_compute_pool" "main" {
  display_name     = "standard_compute_pool"
  cloud            = "AWS"
  region           = "us-east-1"
  max_cfu          = 5
  environment {
    id = confluent_environment.development.id
  }
}
```

<!-- schema generated by tfplugindocs -->
## Argument Reference

The following arguments are supported:

- `display_name` - (Required String) The name of the Flink Compute Pool.
- `cloud` - (Required String) The cloud service provider that runs the Flink Compute Pool.
- `region` - (Required String) The cloud service provider region that hosts the Flink Compute Pool.
- `max_cfu` - (Required Integer) Maximum number of Confluent Flink Units (CFUs) that the Flink compute pool should auto-scale to. The accepted values are: `5`, `10`, `20`, `30`, `40` and `50`.
- `environment` (Required Configuration Block) supports the following:
  - `id` - (Required String) The ID of the Environment that the Flink Compute Pool belongs to, for example, `env-abc123`.

## Attributes Reference

In addition to the preceding arguments, the following attributes are exported:

- `id` - (Required String) The ID of the Flink Compute Pool, for example, `lfcp-abc123`.
- `api_version` - (Required String) The API Version of the schema version of the Flink Compute Pool, for example, `fcpm/v2`.
- `kind` - (Required String) The kind of the Flink Compute Pool, for example, `ComputePool`.
- `resource_name` - (Required String) The Confluent Resource Name of the Flink Compute Pool.

## Import

-> **Note:** `CONFLUENT_CLOUD_API_KEY` and `CONFLUENT_CLOUD_API_SECRET` environment variables must be set before importing a Flink Compute Pool.

You can import a Flink Compute Pool by using Environment ID and Flink Compute Pool ID, in the format `<Environment ID>/<Flink Compute Pool ID>`. The following example shows how to import a Flink Compute Pool:

```shell
$ export CONFLUENT_CLOUD_API_KEY="<cloud_api_key>"
$ export CONFLUENT_CLOUD_API_SECRET="<cloud_api_secret>"
$ terraform import confluent_flink_compute_pool.main env-abc123/lfcp-abc123
```

!> **Warning:** Do not forget to delete terminal command history afterwards for security purposes.
