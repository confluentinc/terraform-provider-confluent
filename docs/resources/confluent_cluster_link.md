---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "confluent_cluster_link Resource - terraform-provider-confluent"
subcategory: ""
description: |-
  
---

# confluent_cluster_link Resource

[![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)

`confluent_cluster_link` provides a Cluster Link resource that enables creating and deleting Cluster Links on a Kafka cluster on Confluent Cloud.

-> **Note:** It is recommended to set `lifecycle { prevent_destroy = true }` on production instances to prevent accidental cluster link deletion. This setting rejects plans that would destroy or recreate the cluster link. Read more about it in the [Terraform docs](https://www.terraform.io/language/meta-arguments/lifecycle#prevent_destroy).

## Example Usage

```terraform
// https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#create-a-cluster-link-in-bidirectional-mode
resource "confluent_cluster_link" "east-to-west" {
  link_name = "bidirectional-link"
  link_mode = "BIDIRECTIONAL"
  local_kafka_cluster {
    id            = data.confluent_kafka_cluster.east.id
    rest_endpoint = data.confluent_kafka_cluster.east.rest_endpoint
    credentials {
      key    = confluent_api_key.app-manager-east-cluster-api-key.id
      secret = confluent_api_key.app-manager-east-cluster-api-key.secret
    }
  }

  remote_kafka_cluster {
    id                 = data.confluent_kafka_cluster.west.id
    bootstrap_endpoint = data.confluent_kafka_cluster.west.bootstrap_endpoint
    credentials {
      key    = confluent_api_key.app-manager-west-cluster-api-key.id
      secret = confluent_api_key.app-manager-west-cluster-api-key.secret
    }
  }

  lifecycle {
    prevent_destroy = true
  }
}

resource "confluent_cluster_link" "west-to-east" {
  link_name = "bidirectional-link"
  link_mode = "BIDIRECTIONAL"
  local_kafka_cluster {
    id            = data.confluent_kafka_cluster.west.id
    rest_endpoint = data.confluent_kafka_cluster.west.rest_endpoint
    credentials {
      key    = confluent_api_key.app-manager-west-cluster-api-key.id
      secret = confluent_api_key.app-manager-west-cluster-api-key.secret
    }
  }

  remote_kafka_cluster {
    id                 = data.confluent_kafka_cluster.east.id
    bootstrap_endpoint = data.confluent_kafka_cluster.east.bootstrap_endpoint
    credentials {
      key    = confluent_api_key.app-manager-east-cluster-api-key.id
      secret = confluent_api_key.app-manager-east-cluster-api-key.secret
    }
  }

  lifecycle {
    prevent_destroy = true
  }
}
```

<!-- schema generated by tfplugindocs -->
## Argument Reference

The following arguments are supported:

- `link_name` - (Required String) The name of the cluster link, for example, `my-cluster-link`.
- `source_kafka_cluster` - (Optional Configuration Block) supports the following:
  - `id` - (Required String) The ID of the source Kafka cluster, for example, `lkc-abc123`.
  - `rest_endpoint` - (Optional String) The REST endpoint of the source Kafka cluster, for example, `https://pkc-00000.us-central1.gcp.confluent.cloud:443`).
  - `bootstrap_endpoint` - (Optional String) The bootstrap endpoint of the source Kafka cluster, for example, `SASL_SSL://pkc-00000.us-central1.gcp.confluent.cloud:9092` or `pkc-00000.us-central1.gcp.confluent.cloud:9092`).
  - `credentials` (Optional Configuration Block) supports the following:
    - `key` - (Required String) The Kafka API Key.
    - `secret` - (Required String, Sensitive) The Kafka API Secret.
- `destination_kafka_cluster` - (Optional Configuration Block) supports the following:
  - `id` - (Required String) The ID of the destination Kafka cluster, for example, `lkc-abc123`.
  - `rest_endpoint` - (Optional String) The REST endpoint of the destination Kafka cluster, for example, `https://pkc-00000.us-central1.gcp.confluent.cloud:443`).
  - `bootstrap_endpoint` - (Optional String) The bootstrap endpoint of the destination Kafka cluster, for example, `SASL_SSL://pkc-00000.us-central1.gcp.confluent.cloud:9092` or `pkc-00000.us-central1.gcp.confluent.cloud:9092`).
  - `credentials` (Required Configuration Block) supports the following:
    - `key` - (Required String) The Kafka API Key.
    - `secret` - (Required String, Sensitive) The Kafka API Secret.
- `local_kafka_cluster` - (Optional Configuration Block) supports the following:
  - `id` - (Required String) The ID of the local Kafka cluster, for example, `lkc-abc123`.
  - `rest_endpoint` - (Optional String) The REST endpoint of the local Kafka cluster, for example, `https://pkc-00000.us-central1.gcp.confluent.cloud:443`).
  - `bootstrap_endpoint` - (Optional String) The bootstrap endpoint of the local Kafka cluster, for example, `SASL_SSL://pkc-00000.us-central1.gcp.confluent.cloud:9092` or `pkc-00000.us-central1.gcp.confluent.cloud:9092`).
  - `credentials` (Optional Configuration Block) supports the following:
    - `key` - (Required String) The Kafka API Key.
    - `secret` - (Required String, Sensitive) The Kafka API Secret.
- `remote_kafka_cluster` - (Optional Configuration Block) supports the following:
  - `id` - (Required String) The ID of the remote Kafka cluster, for example, `lkc-abc123`.
  - `rest_endpoint` - (Optional String) The REST endpoint of the remote Kafka cluster, for example, `https://pkc-00000.us-central1.gcp.confluent.cloud:443`).
  - `bootstrap_endpoint` - (Optional String) The bootstrap endpoint of the remote Kafka cluster, for example, `SASL_SSL://pkc-00000.us-central1.gcp.confluent.cloud:9092` or `pkc-00000.us-central1.gcp.confluent.cloud:9092`).
  - `credentials` (Required Configuration Block) supports the following:
    - `key` - (Required String) The Kafka API Key.
    - `secret` - (Required String, Sensitive) The Kafka API Secret.
- `link_mode` (Optional String) The mode of the cluster link. The supported values are `"DESTINATION"`, `"SOURCE"`, and `"BIDIRECTIONAL"`. Defaults to `"DESTINATION"`.
- `connection_mode` (Optional String) The connection mode of the cluster link. The supported values are `"INBOUND"` and `"OUTBOUND"`. Defaults to `"OUTBOUND"`.
- `config` - (Optional Map) The custom cluster link settings to set:
  - `name` - (Required String) The setting name, for example, `acl.sync.ms`.
  - `value` - (Required String) The setting value, for example, `12345`.

-> **Note:** Use the `local_kafka_cluster` and `remote_kafka_cluster` blocks for [bidirectional links](https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#bidirectional-mode). Use `source_kafka_cluster` and `destination_kafka_cluster` for source-initiated and destination-initiated cluster links.

-> **Note:** For more information on the cluster link settings, see [Cluster Linking Configuration on Confluent Cloud](https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#configuring-cluster-link-behavior).

-> **Note:** A Kafka API key consists of a key and a secret. Kafka API keys are required to interact with Kafka clusters in Confluent Cloud. Each Kafka API key is valid for one specific Kafka cluster.

-> **Note:** To rotate a Kafka API key, create a new Kafka API key, update the `credentials` block in all configuration files to use the new Kafka API key, run `terraform apply -target="confluent_cluster_link.example"`, and remove the old Kafka API key. Alternatively, in case the old Kafka API Key was deleted already, you might need to run `terraform plan -refresh=false -target="confluent_cluster_link.example" -out=rotate-kafka-api-key` and `terraform apply rotate-kafka-api-key` instead.

!> **Warning:** Terraform doesn't encrypt the sensitive `credentials` value of the `confluent_cluster_link` resource, so you must keep your state file secure to avoid exposing it. Refer to the [Terraform documentation](https://www.terraform.io/docs/language/state/sensitive-data.html) to learn more about securing your state file.

-> **Note:** See [Supported Cluster Types](https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/index.html#supported-cluster-types) to determine supported options for source and destination clusters.

-> **Note:** Exactly one from the `rest_endpoint` and `bootstrap_endpoint` attributes must be specified.

## Attributes Reference

In addition to the preceding arguments, the following attributes are exported:

- `id` - (Required String) The composite ID of the Cluster Link resource, in the format `<Kafka cluster ID>/<Cluster link name>`, for example, `lkc-abc123/my-cluster-link`.
- `cluster_link_id` - (Required String) The actual Cluster Link ID assigned from Confluent Cloud that uniquely represents a link between two Kafka clusters, for example, `qz0HDEV-Qz2B5aPFpcWQJQ`.

## Import

You can import a Kafka mirror topic by using the cluster link name, cluster link mode, cluster link connection mode,
source (or local for bidirectional cluster links) Kafka cluster ID, and destination (or remote  for bidirectional cluster links) Kafka cluster ID, in the format `<Cluster link name>/<Cluster link mode>/<Cluster connection mode>/<Source (Local) Kafka cluster ID>/<Destination (Remote) Kafka cluster ID>`, for example:

```shell
# Option #1 when using source-initiated or destination-initiated cluster links
$ export IMPORT_SOURCE_KAFKA_BOOTSTRAP_ENDPOINT="<source_kafka_bootstrap_endpoint>"
$ export IMPORT_SOURCE_KAFKA_API_KEY="<source_kafka_api_key>"
$ export IMPORT_SOURCE_KAFKA_API_SECRET="<source_kafka_api_secret>"
$ export IMPORT_DESTINATION_KAFKA_REST_ENDPOINT="<destination_kafka_rest_endpoint>"
$ export IMPORT_DESTINATION_KAFKA_API_KEY="<destination_kafka_api_key>"
$ export IMPORT_DESTINATION_KAFKA_API_SECRET="<destination_kafka_api_secret>"
$ terraform import confluent_cluster_link.my_cluster_link my-cluster-link/DESTINATION/OUTBOUND/lkc-abc123/lkc-xyz456
```

```shell
# Option #2 when using bidirectional cluster links
$ export IMPORT_LOCAL_KAFKA_BOOTSTRAP_ENDPOINT="<local_kafka_bootstrap_endpoint>"
$ export IMPORT_LOCAL_KAFKA_API_KEY="<local_kafka_api_key>"
$ export IMPORT_LOCAL_KAFKA_API_SECRET="<local_kafka_api_secret>"
$ export IMPORT_REMOTE_KAFKA_REST_ENDPOINT="<remote_kafka_rest_endpoint>"
$ export IMPORT_REMOTE_KAFKA_API_KEY="<remote_kafka_api_key>"
$ export IMPORT_REMOTE_KAFKA_API_SECRET="<remote_kafka_api_secret>"
$ terraform import confluent_cluster_link.my_cluster_link my-cluster-link/BIDIRECTIONAL/OUTBOUND/lkc-abc123/lkc-xyz456
```

!> **Warning:** Do not forget to delete terminal command history afterwards for security purposes.

## Getting Started
The following end-to-end examples might help to get started with `confluent_cluster_link` resource:
  * [`destination-initiated-cluster-link-rbac`](https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/destination-initiated-cluster-link-rbac): An example of setting up a _destination_ initiated cluster link with a mirror topic
  * [`source-initiated-cluster-link-rbac`](https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/source-initiated-cluster-link-rbac): An example of setting up a _source_ initiated cluster link with a mirror topic
  * [`regular-bidirectional-cluster-link-rbac`](https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/regular-bidirectional-cluster-link-rbac): An example of setting up a bidirectional cluster link with 2 mirror topics
  * [`advanced-bidirectional-cluster-link-rbac`](https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/regular-bidirectional-cluster-link-rbac): An example of setting up a bidirectional cluster link with 2 mirror topics ([advanced option](https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#create-a-cluster-link-in-bidirectional-mode))

See [Cluster Linking on Confluent Cloud](https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/index.html) to learn more about Cluster Linking on Confluent Cloud.
